{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Spark Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits and Referecens:\n",
    "\n",
    "- Learning Spark by Holden Karau, Andy Konwinski, Patrick Wendell, and Matei Zaharia (O’Reilly). Copyright 2015 Databricks, 978-1-449-35862-4.\n",
    "- Spark: The Definitive Guide by Bill Chambers and Matei Zaharia (O’Reilly). Copyright 2018 Databricks, Inc., 978-1-491-91221-8.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Getting started: The SparkSession and the Spark UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "# Change the path to the Spark folder accordingly\n",
    "findspark.init(spark_home=\"/home/ubuntu/software/spark-2.2.1-bin-hadoop2.7/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/ubuntu/movielens_v2/movielens/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np # We'll be using numpy for some numeric operations\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark provides a SparkContext\n",
    "sc = pyspark.SparkContext(master=\"local[*]\", appName=\"tour\")\n",
    "# Now you can go to http://localhost:4040/ and see the Spark UI!\n",
    "# Try re-running this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To try the SparkContext with other masters first stop the one that is already running\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **local**: Run Spark locally with one worker thread (i.e. no parallelism at all).\n",
    "- **local[K]**: Run Spark locally with K worker threads (ideally, set this to the number of cores on your machine).\n",
    "- **local[*]**: Run Spark locally with as many worker threads as logical cores on your machine.\n",
    "- **spark://HOST:PORT**: Connect to the given Spark standalone cluster master. The port must be whichever one your master is configured to use, which is 7077 by default.\n",
    "- **mesos://HOST:PORT**: Connect to the given Mesos cluster. The port must be whichever one your is configured to use, which is 5050 by default. Or, for a Mesos cluster using ZooKeeper, use mesos://zk://.... To submit with --deploy-mode cluster, the HOST:PORT should be configured to connect to the MesosClusterDispatcher.\n",
    "- **yarn**: Connect to a YARN cluster in client or cluster mode depending on the value of --deploy-mode. The cluster location will be found based on the HADOOP_CONF_DIR or YARN_CONF_DIR variable.\n",
    "- **yarn-client**: Equivalent to yarn with --deploy-mode client, which is preferred to `yarn-client`\n",
    "- **yarn-cluster**: Equivalent to yarn with --deploy-mode cluster, which is preferred to `yarn-cluster`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating RDDS\n",
    "\n",
    "We saw that we can create RDDs by loading files from disk. We can also create RDDs from Python collections or transforming other RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method parallelize in module pyspark.context:\n",
      "\n",
      "parallelize(c, numSlices=None) method of pyspark.context.SparkContext instance\n",
      "    Distribute a local Python collection to form an RDD. Using xrange\n",
      "    is recommended if the input represents a range for performance.\n",
      "    \n",
      "    >>> sc.parallelize([0, 2, 3, 4, 6], 5).glom().collect()\n",
      "    [[0], [2], [3], [4], [6]]\n",
      "    >>> sc.parallelize(xrange(0, 6, 2), 5).glom().collect()\n",
      "    [[], [0], [], [2], [4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sc.parallelize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an RDD from in-memory objects:\n",
    "l_numbers = np.arange(0,100000)\n",
    "numbers = sc.parallelize(l_numbers) # creation of RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = sc.textFile(os.path.join(data_folder, \"ratings.csv\")).filter(lambda x: \"movie_id\" not in x) # load data from a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD Transformations and Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of RDD operations in Spark: **transformations** and **actions**.\n",
    "- Transfromations: Create new RDDs from other RDDs. \n",
    "- Actions: Extract information from RDDs and return it to the driver program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method map in module pyspark.rdd:\n",
      "\n",
      "map(f, preservesPartitioning=False) method of pyspark.rdd.PipelinedRDD instance\n",
      "    Return a new RDD by applying a function to each element of this RDD.\n",
      "    \n",
      "    >>> rdd = sc.parallelize([\"b\", \"a\", \"c\"])\n",
      "    >>> sorted(rdd.map(lambda x: (x, 1)).collect())\n",
      "    [('a', 1), ('b', 1), ('c', 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ratings.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_splitted = ratings.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[66] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_splitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method take in module pyspark.rdd:\n",
      "\n",
      "take(num) method of pyspark.rdd.PipelinedRDD instance\n",
      "    Take the first num elements of the RDD.\n",
      "    \n",
      "    It works by first scanning one partition, and use the results from\n",
      "    that partition to estimate the number of additional partitions needed\n",
      "    to satisfy the limit.\n",
      "    \n",
      "    Translated from the Scala implementation in RDD#take().\n",
      "    \n",
      "    .. note:: this method should only be used if the resulting array is expected\n",
      "        to be small, as all the data is loaded into the driver's memory.\n",
      "    \n",
      "    >>> sc.parallelize([2, 3, 4, 5, 6]).cache().take(2)\n",
      "    [2, 3]\n",
      "    >>> sc.parallelize([2, 3, 4, 5, 6]).take(10)\n",
      "    [2, 3, 4, 5, 6]\n",
      "    >>> sc.parallelize(range(100), 100).filter(lambda x: x > 90).take(3)\n",
      "    [91, 92, 93]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ratings.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method collect in module pyspark.rdd:\n",
      "\n",
      "collect() method of pyspark.rdd.PipelinedRDD instance\n",
      "    Return a list that contains all of the elements in this RDD.\n",
      "    \n",
      "    .. note:: This method should only be used if the resulting array is expected\n",
      "        to be small, as all the data is loaded into the driver's memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ratings.collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method count in module pyspark.rdd:\n",
      "\n",
      "count() method of pyspark.rdd.PipelinedRDD instance\n",
      "    Return the number of elements in this RDD.\n",
      "    \n",
      "    >>> sc.parallelize([2, 3, 4]).count()\n",
      "    3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ratings.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_splitted_top = ratings_splitted.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_splitted_res = ratings_splitted.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_count = ratings_splitted.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lambda expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Lambda expressions](https://docs.python.org/3.5/howto/functional.html#small-functions-and-the-lambda-expression) are an easy way to write short functions in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda line: 'Spark' in line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(\"we are learning park\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(line):\n",
    "    return 'Spark' in line\n",
    "f(\"we are learning Spark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try to get the zombie movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpedia_movies = sc.textFile(os.path.join(data_folder, \"dbpedia.csv\")) # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count only lines that mention \"Spark\"\n",
    "zombie_movies= dbpedia_movies.filter(lambda line: 'zombie' in line).map(lambda x: x.split(\",\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[71] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zombie_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Last Dance (1996)',\n",
       " 'Braindead (1992)',\n",
       " 'House (1986)',\n",
       " 'Night of the Comet (1984)',\n",
       " 'Phantasm (1979)',\n",
       " 'Night of the Creeps (1986)']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zombie_movies.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy evaluation\n",
    "\n",
    "RDDs are **evaluated lazily**. This means that Spark will not materialize an RDD until it has to perform an action. In the example below, `primesRDD` is not evaluated until action `collect()` is performed on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(num):\n",
    "    \"\"\" return True if num is prime, False otherwise\"\"\"\n",
    "    if num < 1 or num % 1 != 0:\n",
    "        raise Exception(\"invalid argument\")\n",
    "    for d in range(2, int(np.sqrt(num) + 1)):\n",
    "        if num % d == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbersRDD = sc.parallelize(range(1, 1000000)) # creation of RDD\n",
    "primesRDD = numbersRDD.filter(is_prime) # transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primesRDD has not been materialized until this point\n",
    "primes = primesRDD.collect() # action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43]\n",
      "[1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43]\n"
     ]
    }
   ],
   "source": [
    "print(primes[0:15])\n",
    "print(primesRDD.take(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence\n",
    "\n",
    "RDDs are **ephemeral** by default, i.e. there is no guarantee they will remain in memory after they are materialized. If we want them to `persist` in memory, possibly to query them repeatedly or use them in multiple operations, we can ask Spark to do this by calling `persist()` on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "primesRDD_persisted = numbersRDD.filter(is_prime).persist() # transformation # we're asking Spark to keep this RDD in memory. Note that cache is the same but as using persist for memory. However, persist allows you to define other types of storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78499 prime numbers\n",
      "Here are some of them:\n"
     ]
    }
   ],
   "source": [
    "print(\"Found\", primesRDD_persisted.count(), \"prime numbers\") # first action -- causes primesRDD_persisted to be materialized\n",
    "print(\"Here are some of them:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67]\n"
     ]
    }
   ],
   "source": [
    "print(primesRDD_persisted.collect()[0:20]) # second action - RDD is already in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to collect `primesRDD`? Let's time the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 s ± 69.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "primes = primesRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took about 1.8s. That's because Spark had to evaluate `primesRDD` before performing `collect` on it.\n",
    "\n",
    "How long would it take if `primesRDD_persisted` was already in memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ms ± 2.18 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "primes = primesRDD_persisted.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took about 20ms to collect `primesRDD_persisted`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## map and flatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sc.textFile(os.path.join(data_folder, \"dbpedia.csv\")).filter(lambda x: \"movie_id\" not in x)\n",
    "\n",
    "words_map = words.map(lambda phrase: phrase.split(\" \"))\n",
    "\n",
    "l_words = words_map.collect() # This returns a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3,Grumpier',\n",
       " 'Old',\n",
       " 'Men',\n",
       " '(1995),http://dbpedia.org/resource/Grumpier_Old_Men,http://dbpedia.org/data/Grumpier_Old_Men.json,\"{\"\"abstract\"\":',\n",
       " '\"\"Grumpier',\n",
       " 'Old',\n",
       " 'Men',\n",
       " 'is',\n",
       " 'a',\n",
       " '1995']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_words[1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,Jumanji',\n",
       " '(1995),http://dbpedia.org/resource/Jumanji,http://dbpedia.org/data/Jumanji.json,\"{\"\"abstract\"\":',\n",
       " '\"\"Jumanji',\n",
       " 'is',\n",
       " 'a',\n",
       " '1995',\n",
       " 'American',\n",
       " 'family',\n",
       " 'adventure',\n",
       " 'film']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_flatmap = words.flatMap(lambda phrase: phrase.split(\" \"))\n",
    "words_flatmap.collect()[0:10] # This returns a list withe the combined elements of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('(1995),http://dbpedia.org/resource/Jumanji,http://dbpedia.org/data/Jumanji.json,\"{\"\"abstract\"\":',\n",
       "  1),\n",
       " ('is', 6302),\n",
       " ('1995', 316),\n",
       " ('American', 2176),\n",
       " ('family', 156),\n",
       " ('It', 2501),\n",
       " ('an', 1377),\n",
       " ('adaptation', 190),\n",
       " ('of', 9920),\n",
       " ('1981', 64),\n",
       " ('book', 198),\n",
       " ('name', 333),\n",
       " ('Chris', 122),\n",
       " ('Allsburg.', 1),\n",
       " ('The', 7332),\n",
       " ('was', 5728),\n",
       " ('Greg', 19),\n",
       " ('Jonathan', 66),\n",
       " ('Jim', 131),\n",
       " ('Dunst,', 5),\n",
       " ('Pierce,', 5),\n",
       " ('Alan', 122),\n",
       " ('Hyde,', 3),\n",
       " ('Bebe', 6),\n",
       " ('Industrial', 15),\n",
       " ('Magic', 20),\n",
       " ('Amalgamated', 2),\n",
       " ('Dynamics', 2),\n",
       " ('animatronics', 3),\n",
       " ('dedicated', 32),\n",
       " ('visual', 45),\n",
       " ('L.', 113),\n",
       " ('before', 247),\n",
       " (\"film's\", 509),\n",
       " ('release.', 53),\n",
       " ('story', 687),\n",
       " ('centers', 63),\n",
       " ('young', 201),\n",
       " ('Parrish,', 1),\n",
       " ('in', 7662),\n",
       " ('board', 12),\n",
       " ('his', 1652),\n",
       " ('best', 175),\n",
       " ('Whittle', 1),\n",
       " ('years', 197),\n",
       " ('Judy', 16),\n",
       " ('unwittingly', 7),\n",
       " ('now-adult', 1),\n",
       " ('Alan.', 1),\n",
       " ('tracking', 9),\n",
       " ('down', 59),\n",
       " ('resolve', 1),\n",
       " ('finish', 6),\n",
       " ('reverse', 3),\n",
       " ('destruction', 8),\n",
       " ('New', 455),\n",
       " ('Hampshire.', 2),\n",
       " ('took', 128),\n",
       " ('Columbia.', 2),\n",
       " ('Despite', 86),\n",
       " ('$262,797,249', 1),\n",
       " ('$65', 4),\n",
       " ('movie', 453),\n",
       " ('Jumanji', 1),\n",
       " ('titled', 78),\n",
       " ('Zathura', 1),\n",
       " ('released;', 2),\n",
       " ('adapted', 240),\n",
       " ('book.', 10),\n",
       " ('development', 45),\n",
       " ('Dwayne', 3),\n",
       " ('Hart,', 2),\n",
       " ('Jack', 204),\n",
       " ('Black', 60),\n",
       " ('cast', 297),\n",
       " ('as-of-yet', 1),\n",
       " ('unspecified', 4),\n",
       " ('\"\"caption\"\":', 2717),\n",
       " ('\"\"Theatrical', 1793),\n",
       " ('poster\"\",', 2131),\n",
       " ('\"\"studio\"\":', 1729),\n",
       " ('[\"\"Interscope_Communications\"\",', 3),\n",
       " ('\"\"*', 485),\n",
       " ('Teitler', 1),\n",
       " ('Film\"\"],', 9),\n",
       " ('\"\"country\"\":', 2984),\n",
       " ('\"\"United', 2338),\n",
       " ('\"\"language\"\":', 3086),\n",
       " ('\"\"English\"\",', 2493),\n",
       " ('\"\"type\"\":', 218),\n",
       " ('\"\"Film', 110),\n",
       " ('score\"\",', 12),\n",
       " ('\"\"writer\"\":', 2892),\n",
       " ('\"\"starring\"\":', 2893),\n",
       " ('\"\"Bebe_Neuwirth\"\",', 5),\n",
       " ('\"\"Jonathan_Hyde\"\",', 4),\n",
       " ('\"\"distributor\"\":', 2963),\n",
       " ('\"\"Robert_Dalva\"\",', 2),\n",
       " ('\"\"producer\"\":', 2934),\n",
       " ('\"\"Robert_W._Cort\"\"],', 3),\n",
       " ('\"\"budget\"\":', 2032),\n",
       " ('\"\"subject\"\":', 3135),\n",
       " ('[\"\"Category:English-language_films\"\",', 162),\n",
       " ('\"\"Category:American_adventure_comedy_films\"\",', 31),\n",
       " ('\"\"Category:Film_scores_by_James_Horner\"\",', 38),\n",
       " ('\"\"Category:Films_shot_in_New_Hampshire\"\",', 7),\n",
       " ('\"\"Category:Films_directed_by_Joe_Johnston\"\",', 5),\n",
       " ('\"\"Category:Time_loop_films\"\",', 5),\n",
       " ('\"\"Category:Films_set_in_New_Hampshire\"\",', 8),\n",
       " ('\"\"Category:American_fantasy_adventure_films\"\",', 19),\n",
       " ('\"\"Category:Films_set_in_1995\"\",', 10),\n",
       " ('\"\"Category:Alternate_timeline_films\"\",', 5),\n",
       " ('\"\"Category:Fictional_games\"\",', 1),\n",
       " ('\"\"Category:1995_films\"\",', 193),\n",
       " ('\"\"Category:Films_using_computer-generated_imagery\"\",', 21),\n",
       " ('\"\"Category:Films_about_siblings\"\",', 7),\n",
       " ('\"\"Category:Films_based_on_children\\'s_books\"\",', 31),\n",
       " ('3,Grumpier', 1),\n",
       " ('Old', 36),\n",
       " ('(1995),http://dbpedia.org/resource/Grumpier_Old_Men,http://dbpedia.org/data/Grumpier_Old_Men.json,\"{\"\"abstract\"\":',\n",
       "  1),\n",
       " ('\"\"Grumpier', 2),\n",
       " ('romantic', 320),\n",
       " ('comedy', 814),\n",
       " ('1993', 171),\n",
       " ('Men.', 1),\n",
       " ('Lemmon,', 11),\n",
       " ('Walter', 72),\n",
       " ('Sophia', 4),\n",
       " ('Burgess', 10),\n",
       " ('Hannah,', 11),\n",
       " ('Pollak,', 8),\n",
       " ('Katie', 6),\n",
       " ('Morgan', 31),\n",
       " ('Guilbert.', 1),\n",
       " ('Howard', 91),\n",
       " ('Mark', 135),\n",
       " ('Steven', 108),\n",
       " ('Johnson', 22),\n",
       " ('music', 217),\n",
       " ('score', 160),\n",
       " ('Silvestri.', 3),\n",
       " ('motion', 59),\n",
       " ('already', 23),\n",
       " ('suffering', 12),\n",
       " (\"Alzheimer's\", 2),\n",
       " ('gently', 1),\n",
       " ('film.\"\",', 96),\n",
       " ('\"\"wordnet_type\"\":', 2562),\n",
       " ('Men\"\",', 9),\n",
       " ('\"\"Mark_Steven_Johnson\"\",', 5),\n",
       " ('[\"\"Sophia_Loren\"\",', 3),\n",
       " ('\"\"Jack_Lemmon\"\",', 9),\n",
       " ('\"\"Daryl_Hannah\"\",', 9),\n",
       " ('\"\"Kevin_Pollak\"\",', 12),\n",
       " ('\"\"Walter_Matthau\"\",', 7),\n",
       " ('\"\"Ann-Margret\"\"],', 3),\n",
       " ('\"\"Howard_Deutch\"\",', 6),\n",
       " ('[\"\"Maryann_Brandon\"\",', 1),\n",
       " ('\"\"Billy_Weber\"\"],', 3),\n",
       " ('\"\"7.1518503E7\"\",', 1),\n",
       " ('\"\"Tak_Fujimoto\"\",', 12),\n",
       " ('\"\"Italian_language\"\",', 3),\n",
       " ('745187343,', 1),\n",
       " ('1934035,', 1),\n",
       " ('\"\"101.0\"\",', 106),\n",
       " ('6060,', 97),\n",
       " ('\"\"2.5E7\"\",', 69),\n",
       " ('[\"\"Category:American_sequel_films\"\",', 11),\n",
       " ('\"\"Category:Films_directed_by_Howard_Deutch\"\",', 5),\n",
       " ('\"\"Category:Buddy_films\"\",', 112),\n",
       " ('\"\"Category:Film_scores_by_Alan_Silvestri\"\",', 39),\n",
       " ('\"\"Category:American_romantic_comedy_films\"\",', 178),\n",
       " ('\"\"Category:Films_set_in_Minnesota\"\",', 17),\n",
       " ('\"\"Category:1990s_romantic_comedy_films\"\",', 130),\n",
       " ('\"\"Category:Films_about_old_age\"\"]}\"', 1),\n",
       " ('4,Waiting', 1),\n",
       " ('Exhale', 2),\n",
       " ('(1995),http://dbpedia.org/resource/Waiting_to_Exhale,http://dbpedia.org/data/Waiting_to_Exhale.json,\"{\"\"abstract\"\":',\n",
       "  1),\n",
       " ('Forest', 14),\n",
       " ('feature', 274),\n",
       " ('starring', 1234),\n",
       " ('Houston', 4),\n",
       " ('Bassett.', 4),\n",
       " ('novel', 643),\n",
       " ('Terry', 43),\n",
       " ('Lela', 4),\n",
       " ('Rochon,', 4),\n",
       " ('Loretta', 4),\n",
       " ('Michael', 491),\n",
       " ('Hines,', 5),\n",
       " ('rounded', 1),\n",
       " ('out', 184),\n",
       " ('rest', 17),\n",
       " ('Edmonds.', 2),\n",
       " ('four', 168),\n",
       " ('female', 30),\n",
       " ('living', 34),\n",
       " ('Arizona', 11),\n",
       " ('area', 12),\n",
       " ('relationships', 19),\n",
       " ('another.', 3),\n",
       " ('them', 97),\n",
       " ('are', 474),\n",
       " ('until', 131),\n",
       " ('feel', 13),\n",
       " ('comfortable', 3),\n",
       " ('man.', 6),\n",
       " ('notable', 54),\n",
       " ('all-African-American', 1),\n",
       " ('Angeles', 58),\n",
       " ('\\\\\"\"social', 1),\n",
       " ('215,', 148),\n",
       " ('[\"\"Terry_McMillan\"\",', 2),\n",
       " ('\"\"Angela_Bassett\"\"],', 3),\n",
       " ('\"\"Richard_Chew\"\",', 6),\n",
       " ('\"\"8.1452156E7\"\",', 1),\n",
       " ('\"\"Babyface_(musician)\"\",', 1),\n",
       " ('745098448,', 1),\n",
       " ('\"\"124.0\"\",', 38),\n",
       " ('[\"\"Ronald_Bass\"\",', 4),\n",
       " ('\"\"Terry_McMillan\"\",', 1),\n",
       " ('\"\"Ezra_Swerdlow\"\"],', 1),\n",
       " ('[\"\"Category:American_films\"\",', 183),\n",
       " ('\"\"Category:Films_set_in_Phoenix,_Arizona\"\",', 4),\n",
       " ('\"\"Category:Screenplays_by_Ronald_Bass\"\",', 11),\n",
       " ('\"\"Category:Novels_by_Terry_McMillan\"\",', 2),\n",
       " ('\"\"Category:American_romantic_drama_films\"\",', 128),\n",
       " ('\"\"Category:20th_Century_Fox_films\"\",', 166),\n",
       " ('\"\"Category:Female_buddy_films\"\",', 20),\n",
       " ('\"\"Category:African-American_films\"\",', 44),\n",
       " ('\"\"Category:Directorial_debut_films\"\"]}\"', 29),\n",
       " ('5,Father', 1),\n",
       " ('II', 141),\n",
       " ('\"\"Father', 6),\n",
       " ('Diane', 35),\n",
       " ('Keaton', 27),\n",
       " ('Father', 11),\n",
       " ('loose', 27),\n",
       " ('1951', 23),\n",
       " (\"Father's\", 2),\n",
       " ('1950.\"\",', 2),\n",
       " ('\"\"id\"\":', 594),\n",
       " ('II\"\",', 17),\n",
       " ('\"\"Nancy_Meyers\"\",', 3),\n",
       " ('\"\"George_Newbern\"\",', 1),\n",
       " ('\"\"Kimberly_Williams-Paisley\"\",', 1),\n",
       " ('\"\"Touchstone_Pictures\"\",', 35),\n",
       " ('\"\"Adam_Bernardi\"\"],', 1),\n",
       " ('[\"\"William_A._Fraker\"\",', 1),\n",
       " ('3303622,', 1),\n",
       " ('\"\"Category:American_film_remakes\"\",', 43),\n",
       " ('\"\"Category:Midlife_crisis_films\"\",', 8),\n",
       " ('\"\"Category:Films_directed_by_Charles_Shyer\"\",', 1),\n",
       " ('\"\"Category:American_comedy_films\"\",', 198),\n",
       " ('\"\"Category:Pregnancy_films\"\",', 13),\n",
       " ('\"\"Category:American_sequel_films\"\"]}\"', 11),\n",
       " ('produced', 742),\n",
       " ('Mann,', 10),\n",
       " ('Niro,', 23),\n",
       " ('Al', 47),\n",
       " ('Val', 16),\n",
       " ('Niro', 19),\n",
       " ('plays', 115),\n",
       " ('McCauley,', 5),\n",
       " ('professional', 26),\n",
       " ('thief,', 4),\n",
       " ('Pacino', 12),\n",
       " ('Vincent', 57),\n",
       " ('Hanna,', 3),\n",
       " ('veteran', 26),\n",
       " ('LAPD', 6),\n",
       " ('detective', 34),\n",
       " (\"McCauley's\", 2),\n",
       " ('central', 29),\n",
       " ('based', 1078),\n",
       " ('Chicago', 37),\n",
       " ('officer', 35),\n",
       " ('pursuit', 13),\n",
       " ('1960s', 30),\n",
       " ('named', 177),\n",
       " ('after', 453),\n",
       " ('named.', 2),\n",
       " ('commercial', 151),\n",
       " ('$67', 4),\n",
       " ('United', 707),\n",
       " ('States', 389),\n",
       " ('$187', 2),\n",
       " ('against', 161),\n",
       " ('$60', 8),\n",
       " ('aggregator', 3),\n",
       " ('Rotten', 35),\n",
       " ('86%', 3),\n",
       " ('positive', 149),\n",
       " ('reviews,', 77),\n",
       " ('engrossing', 2),\n",
       " ('drama', 600),\n",
       " ('confirms', 2),\n",
       " (\"Mann's\", 4),\n",
       " ('genre.\\\\\"\"\"\",', 2),\n",
       " ('\"\"Michael_Mann_(director)\"\",', 5),\n",
       " ('\"\"productionCompanies\"\":', 122),\n",
       " ('Forward', 2),\n",
       " ('\"\"Regency_Enterprises\"\"],', 9),\n",
       " ('\"\"extra\"\":', 113),\n",
       " ('[\"\"Passengers\"\",', 1),\n",
       " ('\"\"Moby\"\",', 2),\n",
       " ('Eno\"\",', 1),\n",
       " ('\"\"Einst\\\\u00fcrzende', 1),\n",
       " ('Neubauten\"\",', 1),\n",
       " ('\"\"Terje', 1),\n",
       " ('Rypdal', 1),\n",
       " ('Chasers\"\",', 2),\n",
       " ('\"\"Kronos', 2),\n",
       " ('Quartet\"\",', 1),\n",
       " ('\"\"Elliot', 13),\n",
       " ('Goldenthal\"\",', 1),\n",
       " ('Brook\"\"],', 1),\n",
       " ('\"\"artist\"\":', 146),\n",
       " ('\"\"various', 26),\n",
       " ('artists\"\",', 79),\n",
       " ('\"\"writingCredits\"\":', 65),\n",
       " ('\"\"yes\"\",', 260),\n",
       " ('\"\"Performer\"\",', 36),\n",
       " ('Original', 158),\n",
       " ('1,', 27),\n",
       " ('\"\"from', 53),\n",
       " ('1992\"\",', 2),\n",
       " ('Mirror', 4),\n",
       " ('Pool,', 1),\n",
       " ('Singles', 2),\n",
       " ('Collection,', 1),\n",
       " ('des', 15),\n",
       " ('Patienten', 1),\n",
       " ('O.', 17),\n",
       " ('T.,', 1),\n",
       " ('1983\"\",', 5),\n",
       " ('Score,', 9),\n",
       " ('1997\"\",', 4),\n",
       " ('1987\"\"],', 1),\n",
       " ('\"\"Elliot_Goldenthal\"\",', 12),\n",
       " ('\"\"cover\"\":', 149),\n",
       " ('\"\"length\"\":', 189),\n",
       " ('\"\"461.0\"\",', 1),\n",
       " ('\"\"236.0\"\",', 8),\n",
       " ('\"\"298.0\"\",', 6),\n",
       " ('\"\"171.0\"\",', 13),\n",
       " ('\"\"141.0\"\",', 21),\n",
       " ('\"\"159.0\"\",', 14),\n",
       " ('\"\"94.0\"\",', 87),\n",
       " ('\"\"216.0\"\",', 24),\n",
       " ('\"\"275.0\"\",', 6),\n",
       " ('\"\"rev\"\":', 146),\n",
       " ('[\"\"Filmtracks.com\"\",', 7),\n",
       " ('\"\"Musicfromthemovies\"\",', 1),\n",
       " ('\"\"thisAlbum\"\":', 113),\n",
       " ('[\"\"Steel', 1),\n",
       " ('Cello', 1),\n",
       " ('\"\"God', 2),\n",
       " ('Over', 34),\n",
       " ('Waters\"\",', 1),\n",
       " ('\"\"Always', 6),\n",
       " ('\"\"Entrada', 1),\n",
       " ('\"\"Of', 4),\n",
       " ('\"\"Mystery', 5),\n",
       " ('\"\"Refinery', 1),\n",
       " ('Surveillance\"\",', 1),\n",
       " ('\"\"Coffee', 1),\n",
       " ('\"\"Armenia\"\",', 1),\n",
       " ('\"\"Run', 4),\n",
       " ('Uphill\"\",', 1),\n",
       " ('\"\"Gloradin\"\",', 1),\n",
       " ('Drowned', 1),\n",
       " ('\"\"Force', 5),\n",
       " ('\"\"Last', 15),\n",
       " ('Nite\"\"],', 1),\n",
       " ('[\"\"Ted_Levine\"\",', 1),\n",
       " ('\"\"Val_Kilmer\"\",', 5),\n",
       " ('\"\"Amy_Brenneman\"\",', 2),\n",
       " ('\"\"Ashley_Judd\"\",', 4),\n",
       " ('\"\"Al_Pacino\"\",', 9),\n",
       " ('\"\"Wes_Studi\"\",', 3),\n",
       " ('\"\"Robert_De_Niro\"\",', 15),\n",
       " ('\"\"Diane_Venora\"\",', 6),\n",
       " ('\"\"Tom_Sizemore\"\"],', 2),\n",
       " ('\"\"wikiPageExternalLink\"\":', 1489),\n",
       " ('\"\"William_Goldenberg\"\"],', 1),\n",
       " ('\"\"Dante_Spinotti\"\",', 12),\n",
       " ('\"\"170.0\"\",', 23),\n",
       " ('\"\"Category:Film_scores_by_Elliot_Goldenthal\"\",', 10),\n",
       " ('\"\"Category:Action_drama_films\"\",', 17),\n",
       " ('\"\"Category:Fictional_portrayals_of_the_Los_Angeles_Police_Department\"\",',\n",
       "  16),\n",
       " ('\"\"Category:Films_about_organized_crime_in_the_United_States\"\",', 17),\n",
       " ('\"\"Category:Films_directed_by_Michael_Mann\"\",', 3),\n",
       " ('\"\"Category:Films_shot_in_California\"\",', 163),\n",
       " ('\"\"Category:1990s_crime_drama_films\"\",', 56),\n",
       " ('\"\"Category:1990s_crime_thriller_films\"\",', 66),\n",
       " ('\"\"Category:1995_films\"\"]}\"', 17),\n",
       " ('7,Sabrina', 1),\n",
       " ('\"\"Sabrina', 2),\n",
       " ('comedy-drama', 225),\n",
       " ('Barbara', 49),\n",
       " ('Benedek', 1),\n",
       " ('1954', 22),\n",
       " ('Sabrina', 4),\n",
       " ('co-written', 129),\n",
       " ('Billy', 76),\n",
       " ('Wilder', 14),\n",
       " ('Audrey', 8),\n",
       " ('Holden,', 8),\n",
       " ('turn', 47),\n",
       " ('upon', 121),\n",
       " ('Fair.', 3),\n",
       " ('Sydney', 22),\n",
       " ('Pollack,', 1),\n",
       " ('Harrison', 30),\n",
       " ('Ford', 25),\n",
       " ('as', 3474),\n",
       " ('Kinnear', 7),\n",
       " ('Dickinson,', 3),\n",
       " ('Crenna,', 6),\n",
       " ('Marchand,', 1),\n",
       " ('Holly,', 5),\n",
       " ('actress', 41),\n",
       " ('Fanny', 6),\n",
       " ('[\"\"Germany\"\",', 8),\n",
       " ('\"\"English\"\"],', 50),\n",
       " ('\"\"John_Wood_(English_actor)\"\",', 3),\n",
       " ('\"\"Julia_Ormond\"\"],', 1),\n",
       " ('\"\"John_Williams\"\",', 35),\n",
       " ('\"\"Giuseppe_Rotunno\"\",', 8),\n",
       " ('745097891,', 1),\n",
       " ('1356982,', 1),\n",
       " ('\"\"127.0\"\",', 31),\n",
       " ('\"\"Sydney_Pollack\"\"],', 2),\n",
       " ('\"\"Category:German_comedy_films\"\",', 8),\n",
       " ('\"\"Category:Paramount_Pictures_films\"\",', 198),\n",
       " ('\"\"Category:German_drama_films\"\",', 16),\n",
       " ('\"\"Category:French-language_films\"\",', 67),\n",
       " ('\"\"Category:Films_produced_by_Scott_Rudin\"\",', 17),\n",
       " ('\"\"Category:Films_set_in_Paris\"\",', 45),\n",
       " ('\"\"Category:Films_directed_by_Sydney_Pollack\"\",', 7),\n",
       " ('8,Tom', 1),\n",
       " ('Tom', 220),\n",
       " ('Thomas,', 23),\n",
       " ('Renfro,', 1),\n",
       " ('Amy', 40),\n",
       " ('Wright.', 5),\n",
       " ('Hewitt', 3),\n",
       " ('produced/co-written', 1),\n",
       " ('worked', 41),\n",
       " ('work,', 13),\n",
       " (\"1993's\", 7),\n",
       " ('Finn).', 1),\n",
       " ('22,', 37),\n",
       " ('murder', 73),\n",
       " ('vicious', 3),\n",
       " ('known', 264),\n",
       " ('\\\\\"\"Injun', 1),\n",
       " ('befriends', 10),\n",
       " ('Finn,', 2),\n",
       " ('boy', 47),\n",
       " ('no', 101),\n",
       " ('family,', 23),\n",
       " ('forced', 27),\n",
       " ('oath,', 1),\n",
       " ('when', 177),\n",
       " ('accused', 13),\n",
       " ('murder.\"\",', 3),\n",
       " ('Bukowski\"\",', 7),\n",
       " ('\"\"Walt_Disney_Pictures\"\",', 76),\n",
       " ('\"\"music\"\":', 283),\n",
       " ('Endelman\"\",', 5),\n",
       " ('[\"\"Stephen_Sommers\"\",', 1),\n",
       " ('\"\"David_Loughery\"\"],', 1),\n",
       " ('[\"\"Brad_Renfro\"\",', 2),\n",
       " ('\"\"Jonathan_Taylor_Thomas\"\"],', 1),\n",
       " ('\"\"http://movies.disney.com/tom-and-huck\"\",', 1),\n",
       " ('\"\"Walt_Disney_Studios_Motion_Pictures\"\",', 226),\n",
       " ('\"\"2.3920048E7\"\",', 1),\n",
       " ('745098931,', 1),\n",
       " ('\"\"92.0\"\",', 89),\n",
       " ('[\"\"Laurence_Mark\"\",', 3),\n",
       " ('5520,', 80),\n",
       " ('\"\"Category:Films_based_on_American_novels\"\",', 222),\n",
       " ('\"\"Category:Screenplays_by_David_Loughery\"\",', 3),\n",
       " ('\"\"Category:Films_directed_by_Peter_Hewitt\"\",', 1),\n",
       " ('\"\"Category:American_adventure_films\"\"]}\"', 5),\n",
       " ('9,Sudden', 1),\n",
       " ('(1995),http://dbpedia.org/resource/Sudden_Death,http://dbpedia.org/data/Sudden_Death.json,\"{\"\"abstract\"\":',\n",
       "  1),\n",
       " ('\"\"First', 14),\n",
       " ('1982', 62),\n",
       " ('action', 276),\n",
       " ('Sylvester', 25),\n",
       " ('Stallone', 16),\n",
       " ('Rambo,', 5),\n",
       " ('Vietnam', 43),\n",
       " ('must', 59),\n",
       " ('rely', 5),\n",
       " ('survival', 6),\n",
       " ('senses', 3),\n",
       " ('law', 13),\n",
       " ('installment', 118),\n",
       " ('series.', 120),\n",
       " ('Brian', 109),\n",
       " ('Crenna', 4),\n",
       " ('appear', 57),\n",
       " ('1982.', 7),\n",
       " ('initial', 61),\n",
       " ('mixed', 155),\n",
       " ('at', 1272),\n",
       " ('office.', 51),\n",
       " ('Since', 32),\n",
       " ('release,', 129),\n",
       " ('critics,', 90),\n",
       " ('roles', 110),\n",
       " ('Dennehy,', 4),\n",
       " ('sequences', 27),\n",
       " ('genre.', 25),\n",
       " ('success', 208),\n",
       " ('consisting', 13),\n",
       " ('three', 278),\n",
       " ('sequels', 48),\n",
       " ('(all', 5),\n",
       " ('Stallone),', 2),\n",
       " ('series,', 122),\n",
       " ('comic', 73),\n",
       " ('books,', 11),\n",
       " ('novels.', 8),\n",
       " ('tentatively', 2),\n",
       " ('Rambo:', 5),\n",
       " ('Last', 69),\n",
       " ('Stand,', 2),\n",
       " ('cancelled', 9),\n",
       " ('January', 82),\n",
       " ('2016', 6),\n",
       " ('stated', 27),\n",
       " ('he', 545),\n",
       " ('\"\"wikiPageRedirects\"\":', 60),\n",
       " ('\"\"Sudden_death\"\",', 1),\n",
       " ('46775167}\"', 1),\n",
       " ('(1995)', 9),\n",
       " ('seventeenth', 1),\n",
       " ('Bond', 92),\n",
       " ('Pierce', 19),\n",
       " ('Brosnan', 8),\n",
       " ('MI6', 13),\n",
       " ('Bond.', 19),\n",
       " ('Campbell', 21),\n",
       " ('series', 351),\n",
       " ('take', 76),\n",
       " ('Fleming.', 10),\n",
       " ('France,', 20),\n",
       " ('other', 274),\n",
       " ('writers.', 4),\n",
       " ('prevent', 16),\n",
       " ('ex-MI6', 1),\n",
       " ('agent,', 3),\n",
       " ('using', 65),\n",
       " ('satellite', 1),\n",
       " ('cause', 7),\n",
       " ('global', 6),\n",
       " ('financial', 82),\n",
       " ('meltdown.', 1),\n",
       " ('GoldenEye', 3),\n",
       " ('hiatus', 2),\n",
       " ('caused', 21),\n",
       " ('legal', 17),\n",
       " ('disputes,', 3),\n",
       " ('during', 332),\n",
       " ('Timothy', 43),\n",
       " ('replaced', 32),\n",
       " ('recast,', 2),\n",
       " ('Dench', 2),\n",
       " ('becoming', 66),\n",
       " ('portray', 25),\n",
       " ('character,', 49),\n",
       " ('replacing', 8),\n",
       " ('Miss', 19),\n",
       " ('Moneypenny', 1),\n",
       " ('Caroline', 16),\n",
       " ('Bliss', 3),\n",
       " ('Desmond', 4),\n",
       " ('Llewelyn', 1),\n",
       " ('only', 299),\n",
       " ('actor', 86),\n",
       " ('reprise', 34),\n",
       " ('Q.', 3),\n",
       " ('dissolution', 1),\n",
       " ('Union', 23),\n",
       " ('end', 69),\n",
       " ('War,', 16),\n",
       " ('plot.', 11),\n",
       " ('accumulated', 5),\n",
       " ('gross', 53),\n",
       " ('considerably', 4),\n",
       " ('than', 187),\n",
       " (\"Dalton's\", 3),\n",
       " ('films,', 104),\n",
       " ('into', 352),\n",
       " ('account.', 1),\n",
       " ('viewing', 6),\n",
       " ('improvement', 1),\n",
       " ('predecessor.', 5),\n",
       " ('award', 62),\n",
       " ('Achievement', 8),\n",
       " ('Special', 29),\n",
       " ('Effects\\\\\"\"', 1),\n",
       " ('Film', 784),\n",
       " (\"Bond's\", 5),\n",
       " ('creator,', 2),\n",
       " ('working', 60),\n",
       " ('Naval', 1),\n",
       " ('Intelligence', 3),\n",
       " ('commander,', 1),\n",
       " ('monitor', 2),\n",
       " ('Civil', 24),\n",
       " ('codenamed', 1),\n",
       " ('Goldeneye.', 1),\n",
       " ('used', 141),\n",
       " ('Jamaica.\"\",', 1),\n",
       " ('France\"\",', 10),\n",
       " ('cinema', 38),\n",
       " ('GoldenEye,', 2),\n",
       " ('Whitear\"\",', 2),\n",
       " ('[\"\"Russian\"\",', 2),\n",
       " ('[\"\"Sean_Bean\"\",', 2),\n",
       " ('\"\"Joe_Don_Baker\"\",', 3),\n",
       " ('\"\"Famke_Janssen\"\",', 4),\n",
       " ('[\"\"United_International_Pictures\"\",', 4),\n",
       " ('\"\"Metro-Goldwyn-Mayer\"\"],', 21),\n",
       " ('\"\"\\\\u00c9ric_Serra\"\",', 3),\n",
       " ('745247481,', 1),\n",
       " ('268833,', 1),\n",
       " ('\"\"130.0\"\",', 36),\n",
       " ('[\"\"Barbara_Broccoli\"\",', 2),\n",
       " ('7800,', 25),\n",
       " ('\"\"5.8E7\"\",', 8),\n",
       " ('\"\"Category:Films_set_in_Saint_Petersburg\"\",', 2),\n",
       " ('\"\"Category:Films_shot_in_England\"\",', 51),\n",
       " ('\"\"Category:Films_set_in_Cuba\"\",', 5),\n",
       " ('\"\"Category:Films_about_terrorism\"\",', 40),\n",
       " ('\"\"Category:Films_shot_in_Monaco\"\",', 4),\n",
       " ('\"\"Category:British_films\"\",', 297),\n",
       " ('\"\"Category:Films_produced_by_Michael_G._Wilson\"\",', 5),\n",
       " ('\"\"Category:British_sequel_films\"\",', 24),\n",
       " ('\"\"Category:Metro-Goldwyn-Mayer_films\"\",', 126),\n",
       " ('\"\"Category:Films_directed_by_Martin_Campbell\"\"]}\"', 1),\n",
       " ('11,\"American', 1),\n",
       " ('President,', 2),\n",
       " ('\"\"The', 1279),\n",
       " ('President', 26),\n",
       " ('Reiner', 13),\n",
       " ('Aaron', 14),\n",
       " ('Sorkin.', 1),\n",
       " ('Douglas,', 20),\n",
       " ('Bening,', 4),\n",
       " ('Sheen,', 12),\n",
       " ('Fox', 59),\n",
       " ('Andrew', 67),\n",
       " ('widower', 5),\n",
       " ('Ellen', 30),\n",
       " ('Wade', 6),\n",
       " ('just', 75),\n",
       " ('D.C.', 6),\n",
       " ('win', 62),\n",
       " ('bill.', 2),\n",
       " ('Composer', 4),\n",
       " ('Marc', 19),\n",
       " ('Shaiman', 5),\n",
       " ('nominated', 374),\n",
       " ('Musical', 33),\n",
       " ('Score', 34),\n",
       " ('Golden', 206),\n",
       " ('Director,', 32),\n",
       " ('Actress', 136),\n",
       " ('Comedy/Musical.', 1),\n",
       " ('Institute', 40),\n",
       " ('ranked', 75),\n",
       " ('Love', 130),\n",
       " ('\"\"Castle_Rock_Entertainment\"\",', 32),\n",
       " ('\"\"Aaron_Sorkin\"\",', 2),\n",
       " ('\"\"David_Paymer\"\",', 7),\n",
       " ('\"\"Michael_Douglas\"\",', 11),\n",
       " ('\"\"Michael_J._Fox\"\",', 7),\n",
       " ('\"\"Samantha_Mathis\"\",', 7),\n",
       " ('\"\"Annette_Bening\"\"],', 3),\n",
       " ('\"\"http://www.whitehousemuseum.org/special/movies.htm#americanpresident\"\",',\n",
       "  1),\n",
       " ('\"\"imdbId\"\":', 979),\n",
       " ('\"\"Universal_Pictures\"\"],', 10),\n",
       " ('\"\"Robert_Leighton_(film_editor)\"\",', 12),\n",
       " ('\"\"John_Seale\"\",', 13),\n",
       " ('\"\"6.2E7\"\",', 5),\n",
       " ('[\"\"Category:Films_about_elections\"\",', 2),\n",
       " ('\"\"Category:Columbia_Pictures_films\"\",', 184),\n",
       " ('\"\"Category:Castle_Rock_Entertainment_films\"\",', 34),\n",
       " ('\"\"Category:Films_directed_by_Rob_Reiner\"\",', 8),\n",
       " ('\"\"Category:American_political_drama_films\"\",', 15),\n",
       " ('Dead', 55),\n",
       " ('\"\"Dracula:', 1),\n",
       " ('satirical', 33),\n",
       " ('Leslie', 38),\n",
       " ('spoof', 5),\n",
       " ('films', 480),\n",
       " ('inspired.', 1),\n",
       " ('this', 302),\n",
       " ('Rudy', 8),\n",
       " ('appears', 59),\n",
       " ('Helsing.', 2),\n",
       " ('include', 49),\n",
       " ('Weber,', 3),\n",
       " ('MacNicol,', 1),\n",
       " ('Bancroft.', 5),\n",
       " ('follows', 203),\n",
       " ('Dracula', 27),\n",
       " ('(1931),', 2),\n",
       " ('Bela', 10),\n",
       " ('Lugosi,', 5),\n",
       " ('Its', 77),\n",
       " ('style', 36),\n",
       " ('production', 248),\n",
       " ('particularly', 32),\n",
       " ('Hammer', 15),\n",
       " ('Horror', 20),\n",
       " ('Fearless', 2),\n",
       " ('Killers', 6),\n",
       " ('(1967)', 1),\n",
       " ('[\"\"Rudy', 2),\n",
       " ('\"\"Steve', 26),\n",
       " ('Haberman\"\"],', 1),\n",
       " ('[\"\"Brooksfilms\"\",', 1),\n",
       " ('\"\"German\"\"],', 6),\n",
       " ('[\"\"Rudy_De_Luca\"\",', 1),\n",
       " ('\"\"Leslie_Nielsen\"\",', 6),\n",
       " ('\"\"Harvey_Korman\"\",', 5),\n",
       " ('\"\"Lysette_Anthony\"\"],', 1),\n",
       " ('\"\"Hummie_Mann\"\",', 2),\n",
       " ('[\"\"Category:Films_set_in_Transylvania\"\",', 1),\n",
       " ('\"\"Category:German-language_films\"\",', 37),\n",
       " ('\"\"Category:American_comedy_horror_films\"\",', 41),\n",
       " ('\"\"Category:1990s_comedy_horror_films\"\",', 18),\n",
       " ('\"\"Category:French_films\"\",', 96),\n",
       " ('\"\"Category:Films_directed_by_Mel_Brooks\"\",', 8),\n",
       " ('\"\"Category:American_satirical_films\"\",', 76),\n",
       " ('\"\"Category:French_comedy_films\"\"]}\"', 3),\n",
       " ('\"\"Balto', 2),\n",
       " ('Amblin', 8),\n",
       " ('Entertainment', 125),\n",
       " ('true', 58),\n",
       " ('save', 35),\n",
       " ('diphtheria', 1),\n",
       " ('epidemic', 3),\n",
       " ('1925', 13),\n",
       " ('run', 41),\n",
       " ('live-action', 42),\n",
       " ('Central', 20),\n",
       " ('City.', 25),\n",
       " ('Amblimation', 3),\n",
       " ('animation', 48),\n",
       " ('studio.', 6),\n",
       " ('Spielberg,', 14),\n",
       " ('Kathleen', 23),\n",
       " ('Kennedy', 18),\n",
       " ('Bonne', 2),\n",
       " ('executive', 67),\n",
       " ('Pixar', 6),\n",
       " ('subsequent', 34),\n",
       " ('home', 115),\n",
       " ('led', 83),\n",
       " ('two', 504),\n",
       " ('II:', 66),\n",
       " ('Quest', 11),\n",
       " ('III:', 42),\n",
       " ('Change', 4),\n",
       " ('last', 194),\n",
       " ('Amblimation.', 1),\n",
       " ('filmed', 243),\n",
       " ('\"\"Cynthia_Weil\"\",', 1),\n",
       " ('\"\"Cliff', 2),\n",
       " ('Elana', 1),\n",
       " ('\"\"Steve_Winwood\"\",', 1),\n",
       " ('Alvin.\"\",', 9),\n",
       " ('\"\"Jan', 8),\n",
       " ('Richter-Friis\"\",', 1),\n",
       " ('\"\"Various', 102),\n",
       " ('\"\"recorded\"\":', 96),\n",
       " ('[\"\"Amblin_Entertainment\"\",', 6),\n",
       " ('\"\"Amblimation\"\"],', 1),\n",
       " ('\"\"totalLength\"\":', 77),\n",
       " ('\"\"Baltocd.jpg\"\",', 1),\n",
       " ('[\"\"142.0\"\",', 3),\n",
       " ('\"\"89.0\"\",', 67),\n",
       " ('\"\"278.0\"\",', 5),\n",
       " ('\"\"245.0\"\"],', 2),\n",
       " ('Wolf\"\",', 7),\n",
       " ('\"\"Rosy', 1),\n",
       " ('Goes', 34),\n",
       " ('Doctor\"\",', 3),\n",
       " ('\"\"Boris', 1),\n",
       " ('Medicine!\"\",', 1),\n",
       " ('Bear\"\",', 1),\n",
       " (\"Epidemic's\", 1),\n",
       " ('Toll\"\",', 1),\n",
       " ('Race\"\",', 4),\n",
       " ('Journey', 14),\n",
       " ('Begins\"\",', 2),\n",
       " ('\"\"Steele\\'s', 1),\n",
       " ('Treachery\"\"],', 1),\n",
       " ('[\"\"Bob_Hoskins\"\",', 2),\n",
       " ('\"\"Phil_Collins\"\",', 1),\n",
       " ('\"\"Bridget_Fonda\"\"],', 1),\n",
       " ('[\"\"http://keyframeonline.com/Animation/Balto/27/\\'\\'Balto\\'\\'\"\",', 1),\n",
       " ('\"\"http://www.balto.tv/index2.html\"\",', 1),\n",
       " ('\"\"http://www.rottentomatoes.com/m/balto/\"\"],', 1),\n",
       " ('\"\"Simon_Wells\"\",', 2),\n",
       " ('\"\"thumbnail\"\":', 247),\n",
       " ('\"\"United_States\"\",', 182),\n",
       " ('[\"\"Category:Amblin_Entertainment_animated_films\"\",', 1),\n",
       " ('\"\"Category:Films_with_live_action_and_animation\"\",', 51),\n",
       " ('\"\"Category:Films_about_animals\"\",', 15),\n",
       " ('\"\"Category:American_adventure_drama_films\"\",', 24),\n",
       " ('\"\"Category:Balto_(film)\"\",', 1),\n",
       " ('\"\"Category:Films_directed_by_Simon_Wells\"\",', 4),\n",
       " ('\"\"Category:Films_set_in_1925\"\",', 3),\n",
       " ('\"\"Category:Mushing_films\"\",', 1),\n",
       " ('\"\"Category:Films_featuring_anthropomorphic_characters\"\",', 86),\n",
       " ('\"\"Category:Northern_films\"\",', 2),\n",
       " ('\"\"Category:Films_set_in_Alaska\"\",', 4),\n",
       " ('\"\"Category:1995_animated_films\"\",', 5),\n",
       " ('\"\"Category:Films_about_dogs\"\"]}\"', 4),\n",
       " ('14,Nixon', 1),\n",
       " ('(1995),http://dbpedia.org/resource/Nixon_(film),http://dbpedia.org/data/Nixon_(film).json,\"{\"\"abstract\"\":',\n",
       "  1),\n",
       " ('\"\"Nixon', 1),\n",
       " ('epic', 72),\n",
       " ('biographical', 57),\n",
       " ('Pictures', 212),\n",
       " ('tells', 191),\n",
       " ('political', 59),\n",
       " ('played', 156),\n",
       " ('Anthony', 89),\n",
       " ('Hopkins.', 3),\n",
       " ('Nixon', 9),\n",
       " ('respects,', 1),\n",
       " ('though', 54),\n",
       " ('begins', 38),\n",
       " ('attempt', 49),\n",
       " ('understand', 12),\n",
       " ('[...]', 6),\n",
       " ('public', 30),\n",
       " ('incomplete', 1),\n",
       " ('record.\\\\\"\"', 2),\n",
       " ('Allen,', 43),\n",
       " ('Annabeth', 3),\n",
       " ('Gish,', 5),\n",
       " ('Marley', 4),\n",
       " ('Powers', 9),\n",
       " ('Boothe,', 4),\n",
       " ('Walsh,', 14),\n",
       " ('E.', 95),\n",
       " ('G.', 59),\n",
       " ('Hoskins,', 7),\n",
       " ('Larry', 65),\n",
       " ('Hagman,', 2),\n",
       " ('Joanna', 13),\n",
       " ('figures', 12),\n",
       " ('Bill', 146),\n",
       " ('Clinton', 6),\n",
       " ('TV', 80),\n",
       " ('footage', 54),\n",
       " ('funeral', 3),\n",
       " ('service.', 2),\n",
       " (\"didn't\", 19),\n",
       " ('perform', 10),\n",
       " ('but', 521),\n",
       " ('Awards:', 21),\n",
       " ('(Anthony', 1),\n",
       " ('presidency,', 1),\n",
       " ('assassination', 11),\n",
       " ('F.', 80),\n",
       " ('thirteen', 5),\n",
       " ('Group\"\",', 13),\n",
       " ('\"\"Cinergi_Pictures\"\",', 3),\n",
       " ('[\"\"Christopher_Wilkinson\"\",', 1),\n",
       " ('\"\"E._G._Marshall\"\",', 3),\n",
       " ('\"\"J._T._Walsh\"\",', 7),\n",
       " ('\"\"James_Woods\"\",', 8),\n",
       " ('\"\"Joan_Allen\"\",', 2),\n",
       " ('\"\"Mary_Steenburgen\"\",', 7),\n",
       " ('\"\"Bob_Hoskins\"\",', 6),\n",
       " ('\"\"David_Hyde_Pierce\"\"],', 1),\n",
       " ('\"\"http://www.whitehousemuseum.org/special/movies.htm#nixon\"\"],', 1),\n",
       " ('\"\"Oliver_Stone\"\",', 12),\n",
       " ('\"\"Buena_Vista_Pictures\"\",', 7),\n",
       " ('[\"\"Brian_Berdan\"\",', 2),\n",
       " ('\"\"Robert_Richardson_(cinematographer)\"\",', 12),\n",
       " ('171078,', 1),\n",
       " ('[\"\"Andrew_G._Vajna\"\",', 3),\n",
       " ('\"\"4.4E7\"\",', 6),\n",
       " ('\"\"Category:American_epic_films\"\",', 57),\n",
       " ('\"\"Category:Watergate_scandal_in_film\"\",', 2),\n",
       " ('\"\"Category:Films_directed_by_Oliver_Stone\"\",', 6),\n",
       " ('\"\"Category:Film_scores_by_John_Williams\"\",', 27),\n",
       " ('\"\"Category:Richard_Nixon_in_film_and_television\"\",', 2),\n",
       " ('\"\"Category:Films_set_in_the_1960s\"\",', 54),\n",
       " ('15,Cutthroat', 1),\n",
       " ('Island', 22),\n",
       " ('Renny', 7),\n",
       " ('Harlin', 3),\n",
       " ('Norman', 41),\n",
       " ('Frost', 6),\n",
       " ('Beckner,', 2),\n",
       " ('A.', 116),\n",
       " ('Evans,', 11),\n",
       " ('Raymond', 27),\n",
       " ('Gideon.', 1),\n",
       " ('Davis,', 26),\n",
       " ('Matthew', 69),\n",
       " ('Langella.', 2),\n",
       " ('companies', 16),\n",
       " ('Germany,', 21),\n",
       " ('Italy.', 5),\n",
       " ('production,', 25),\n",
       " ('involving', 23),\n",
       " ('multiple', 38),\n",
       " ('rewrites', 7),\n",
       " ('whereas', 6),\n",
       " ('high', 102),\n",
       " ('values,', 3),\n",
       " ('sequences,', 14),\n",
       " ('musical', 245),\n",
       " ('praised.', 1),\n",
       " ('adjusted', 7),\n",
       " ('closure,', 1),\n",
       " (\"company's\", 3),\n",
       " ('[\"\"Carolco_Pictures\"\",', 4),\n",
       " ('Forge\\\\n*\"\",', 1),\n",
       " ('Beckner/Gorman', 1),\n",
       " ('Raynold', 3),\n",
       " ('Gideon\"\",', 2),\n",
       " ('Gorman\\\\n*\"\",', 1),\n",
       " ('[\"\"Theatrical', 14),\n",
       " ('\"\"by', 13),\n",
       " ('Italy\"\",', 5),\n",
       " ('\"\"Robert_King_(writer)\"\"],', 1),\n",
       " ('[\"\"Geena_Davis\"\",', 2),\n",
       " ('\"\"Maury_Chaykin\"\",', 8),\n",
       " ('\"\"Matthew_Modine\"\",', 5),\n",
       " ('\"\"Renny_Harlin\"\",', 8),\n",
       " ('\"\"John_Debney\"\",', 16),\n",
       " ('[\"\"Joel_B._Michaels\"\",', 4),\n",
       " ('\"\"Laurence_Mark\"\"],', 2),\n",
       " ('\"\"9.8E7\"\",', 2),\n",
       " ('\"\"Category:American_adventure_films\"\",', 48),\n",
       " ('\"\"Category:German_action_films\"\",', 2),\n",
       " ('\"\"Category:Italian_films\"\",', 49),\n",
       " ('\"\"Category:Films_shot_in_Malta\"\",', 5),\n",
       " ('\"\"Category:Pirate_films\"\",', 8),\n",
       " ('\"\"Category:German_romantic_comedy_films\"\",', 1),\n",
       " ('\"\"Category:Italian_comedy_films\"\",', 1),\n",
       " ('\"\"Category:Films_shot_in_Thailand\"\",', 14),\n",
       " ('\"\"Category:Treasure_hunt_films\"\",', 16),\n",
       " ('\"\"Category:Italian_adventure_films\"\",', 2),\n",
       " ('\"\"Category:Films_set_in_the_17th_century\"\",', 6),\n",
       " ('\"\"Category:Italian_action_films\"\",', 1),\n",
       " ('\"\"Category:Carolco_Pictures_films\"\"]}\"', 1),\n",
       " ('16,Casino', 1),\n",
       " ('Scorsese', 25),\n",
       " ('Sharon', 19),\n",
       " ('Stone.', 10),\n",
       " ('Vegas', 29),\n",
       " ('Nicholas', 42),\n",
       " ('Pileggi,', 8),\n",
       " ('co-wrote', 34),\n",
       " ('Scorsese.', 12),\n",
       " ('following', 137),\n",
       " ('(1973),', 7),\n",
       " ('Taxi', 9),\n",
       " ('Driver', 11),\n",
       " ('Raging', 5),\n",
       " ('(1980),', 3),\n",
       " ('Casino,', 2),\n",
       " ('Rothstein,', 2),\n",
       " ('Jewish', 21),\n",
       " ('handicapper', 2),\n",
       " ('Mob', 7),\n",
       " ('oversee', 3),\n",
       " ('operations', 7),\n",
       " ('Tangiers', 4),\n",
       " ('Casino', 8),\n",
       " ('Vegas.', 5),\n",
       " ('ran', 25),\n",
       " ('Stardust,', 2),\n",
       " ('Hacienda', 2),\n",
       " ('Pesci', 13),\n",
       " ('\\\\\"\"Nicky\\\\\"\"', 2),\n",
       " ('Santoro,', 2),\n",
       " ('real-life', 49),\n",
       " ('Nicky', 5),\n",
       " ('sent', 43),\n",
       " ('make', 101),\n",
       " ('sure', 8),\n",
       " ...]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the flatmap to make a word count\n",
    "words_flatmap.map(\n",
    "    lambda x: (x,1)\n",
    ").reduceByKey(\n",
    "    lambda x,y: x+y\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Set operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[97] at parallelize at PythonRDD.scala:489"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneRDD = sc.parallelize([1, 1, 1, 2, 3, 3, 4, 4])\n",
    "oneRDD.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[98] at parallelize at PythonRDD.scala:489"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otherRDD = sc.parallelize([1, 4, 4, 7])\n",
    "otherRDD.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnionRDD[99] at union at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unionRDD = oneRDD.union(otherRDD)\n",
    "unionRDD.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 3]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneRDD.subtract(otherRDD).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneRDD.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneRDD.intersection(otherRDD).collect() # removes duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 4), (1, 4), (1, 7), (1, 1)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneRDD.cartesian(otherRDD).collect()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([1,43,62,23,52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize([1,43,62,23,52])\n",
    "data.reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3188536"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reduce(lambda x, y: x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3188536"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * 43 * 62 * 23 * 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137823683725010149883130929"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reduce(lambda x, y: x**2 + y**2) # this does NOT compute the sum of squares of RDD elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137823683725010149883130929"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((((1 ** 2 + 43 ** 2) ** 2 + 62 ** 2) **2 + 23 ** 2) **2 + 52 **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.00000000000006"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reduce(lambda x, y: np.sqrt(x**2 + y**2)) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8927"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([1,43,62,23,52]) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method aggregate in module pyspark.rdd:\n",
      "\n",
      "aggregate(zeroValue, seqOp, combOp) method of pyspark.rdd.RDD instance\n",
      "    Aggregate the elements of each partition, and then the results for all\n",
      "    the partitions, using a given combine functions and a neutral \"zero\n",
      "    value.\"\n",
      "    \n",
      "    The functions C{op(t1, t2)} is allowed to modify C{t1} and return it\n",
      "    as its result value to avoid object allocation; however, it should not\n",
      "    modify C{t2}.\n",
      "    \n",
      "    The first function (seqOp) can return a different result type, U, than\n",
      "    the type of this RDD. Thus, we need one operation for merging a T into\n",
      "    an U and one operation for merging two U\n",
      "    \n",
      "    >>> seqOp = (lambda x, y: (x[0] + y, x[1] + 1))\n",
      "    >>> combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
      "    >>> sc.parallelize([1, 2, 3, 4]).aggregate((0, 0), seqOp, combOp)\n",
      "    (10, 4)\n",
      "    >>> sc.parallelize([]).aggregate((0, 0), seqOp, combOp)\n",
      "    (0, 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data.aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq(x,y):\n",
    "    print(x,y,\"seq\")\n",
    "    return x[0] + y, x[1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comb(x,y):\n",
    "    print(x,y,\"comb\")\n",
    "    return x[0] + y[0], x[1] + y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([1,43,62,23,52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) (181, 5) comb\n"
     ]
    }
   ],
   "source": [
    "data = sc.parallelize([1,43,62,23,52], 1) # Try different levels of paralellism\n",
    "aggr = data.aggregate(zeroValue = (0,0),\n",
    "                      seqOp = seq, #\n",
    "                      combOp = comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 5)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggr[0] / aggr[1] # average value of RDD elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method reduceByKey in module pyspark.rdd:\n",
      "\n",
      "reduceByKey(func, numPartitions=None, partitionFunc=<function portable_hash at 0x000001E7C579D378>) method of pyspark.rdd.RDD instance\n",
      "    Merge the values for each key using an associative reduce function.\n",
      "    \n",
      "    This will also perform the merging locally on each mapper before\n",
      "    sending results to a reducer, similarly to a \"combiner\" in MapReduce.\n",
      "    \n",
      "    Output will be partitioned with C{numPartitions} partitions, or\n",
      "    the default parallelism level if C{numPartitions} is not specified.\n",
      "    Default partitioner is hash-partition.\n",
      "    \n",
      "    >>> from operator import add\n",
      "    >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
      "    >>> sorted(rdd.reduceByKey(add).collect())\n",
      "    [('a', 2), ('b', 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pairRDD.reduceByKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$APPL', 201.16), ('$AMZN', 1104.64), ('$GOOG', 706.2)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD = sc.parallelize([('$APPL', 100.64), \n",
    "                          ('$APPL', 100.52), \n",
    "                          ('$GOOG', 706.2), \n",
    "                          ('$AMZN', 552.32), \n",
    "                          ('$AMZN', 552.32) ])\n",
    "\n",
    "pairRDD.reduceByKey(lambda x,y: x + y).collect() # sum of values per key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://github.com/vaquarkhan/vk-wiki-notes/wiki/reduceByKey--vs-groupBykey-vs-aggregateByKey-vs-combineByKey\n",
    "\n",
    "ReduceByKey will aggregate y key before shuffling: \n",
    "![alt text](https://camo.githubusercontent.com/516114b94193cddf7e59bdd5368d6756d30dc8b4/687474703a2f2f7777772e727578697a68616e672e636f6d2f75706c6f6164732f342f342f302f322f34343032333436352f313836363838325f6f7269672e706e67)\n",
    "\n",
    "GroupByKey will shuffle all the value key pairs as the diagrams show: \n",
    "![alt text](https://camo.githubusercontent.com/ed75baabdaee2198d3fc1390e04a5d20bcd2e484/687474703a2f2f7777772e727578697a68616e672e636f6d2f75706c6f6164732f342f342f302f322f34343032333436352f333030393135315f6f7269672e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (inner) join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = sc.textFile(os.path.join(data_folder, \"movies.csv\")).filter(lambda x: \"movie_id\" not in x).map(lambda x: x.split(\",\"))\n",
    "ratings = sc.textFile(os.path.join(data_folder, \"ratings.csv\")).filter(lambda x: \"movie_id\" not in x).map(lambda x: x.split(\",\")[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1193', '5'],\n",
       " ['661', '3'],\n",
       " ['914', '3'],\n",
       " ['3408', '4'],\n",
       " ['2355', '5'],\n",
       " ['1197', '3'],\n",
       " ['1287', '5'],\n",
       " ['2804', '5'],\n",
       " ['594', '4'],\n",
       " ['919', '4']]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', ('Waiting to Exhale (1995)', '3')),\n",
       " ('4', ('Waiting to Exhale (1995)', '3')),\n",
       " ('4', ('Waiting to Exhale (1995)', '1')),\n",
       " ('4', ('Waiting to Exhale (1995)', '4')),\n",
       " ('4', ('Waiting to Exhale (1995)', '1'))]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.join(ratings).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Accumulators\n",
    "\n",
    "This example demonstrates how to use accumulators.\n",
    "The map operations creates an RDD that contains the length of lines in the text file - and while the RDD is materialized, an accumulator keeps track of how many lines are long (longer than $30$ characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3267"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = sc.textFile(os.path.join(data_folder, \"dbpedia.csv\"))\n",
    "long_lines = sc.accumulator(0) # create accumulator\n",
    "\n",
    "def line_data(line):\n",
    "    global long_lines # to reference an accumulator, declare it as global variable\n",
    "    length = len(line)\n",
    "    if \"abstract\" in line:\n",
    "        long_lines += 1 # update the accumulator\n",
    "    return length\n",
    "\n",
    "llengthRDD = text.map(line_data)\n",
    "llengthRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3266"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_lines.value # this is how we obtain the value of the accumulator in the driver program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Accumulator in module pyspark.accumulators object:\n",
      "\n",
      "class Accumulator(builtins.object)\n",
      " |  A shared variable that can be accumulated, i.e., has a commutative and associative \"add\"\n",
      " |  operation. Worker tasks on a Spark cluster can add values to an Accumulator with the C{+=}\n",
      " |  operator, but only the driver program is allowed to access its value, using C{value}.\n",
      " |  Updates from the workers get propagated automatically to the driver program.\n",
      " |  \n",
      " |  While C{SparkContext} supports accumulators for primitive data types like C{int} and\n",
      " |  C{float}, users can also define accumulators for custom types by providing a custom\n",
      " |  L{AccumulatorParam} object. Refer to the doctest of this module for an example.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __iadd__(self, term)\n",
      " |      The += operator; adds a term to this accumulator's value\n",
      " |  \n",
      " |  __init__(self, aid, value, accum_param)\n",
      " |      Create a new Accumulator with a given initial value and AccumulatorParam object\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      Custom serialization; saves the zero value from our AccumulatorParam\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  add(self, term)\n",
      " |      Adds a term to this accumulator's value\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  value\n",
      " |      Get the accumulator's value; only usable in driver program\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(long_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning\n",
    "\n",
    "In the example above, we update the value of an accumulator within a transformation (map). This is **not recommended**, unless for debugging purposes! The reason is that, if there are failures during the materialization of `llengthRDD`, some of its partitions will be re-computed, possibly causing the accumulator to double-count some the the long lines.\n",
    "\n",
    "It is advisable to use accumulators within actions - and particularly with the `foreach` action, as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3267"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = sc.textFile(os.path.join(data_folder, \"dbpedia.csv\"))\n",
    "long_lines_2 = sc.accumulator(0)\n",
    "\n",
    "def line_len(line):\n",
    "    global long_lines_2\n",
    "    length = len(line)\n",
    "    if length > 30:\n",
    "        long_lines_2 += 1\n",
    "\n",
    "text.foreach(line_len)\n",
    "\n",
    "long_lines_2.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast variable\n",
    "\n",
    "We use *broadcast variables* when many operations depend on the same large static object - e.g., a large lookup table that does not change but provides information for other operations. In such cases, we can make a broadcast variable out of the object and thus make sure that the object will be shipped to the cluster only once - and not for each of the operations we'll be using it for.\n",
    "\n",
    "The example below demonstrates the usage of broadcast variables. In this case, we make a broadcast variable out of a dictionary that represents an address table. The tablke is shipped to cluster nodes only once across multiple operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ages_catalog():\n",
    "    return {1: \"Under 18\", 18: \"18-24\", 25: \"25-34\", 35: \"35-44\", 45: \"45-49\", 50: \"50-55\", 56: \"56+\"}\n",
    "ages_catalog = sc.broadcast(load_ages_catalog())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Under 18'), (18, '18-24'), (50, '50-55')]\n",
      "[(35, '35-44'), (50, '50-55'), (1, 'Under 18')]\n"
     ]
    }
   ],
   "source": [
    "def find_age(age_id):\n",
    "    res = None\n",
    "    if age_id in ages_catalog.value:\n",
    "        res = ages_catalog.value[age_id]\n",
    "    return res\n",
    "\n",
    "ages = sc.parallelize([1,18,50])\n",
    "pairRDD = ages.map(lambda age_id: (age_id, find_age(age_id)))\n",
    "print(pairRDD.collect())\n",
    "\n",
    "other_ages = sc.parallelize([35, 50, 1])\n",
    "pairRDD = other_ages.map(lambda age_id: (age_id, find_age(age_id)))\n",
    "print(pairRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id,gender,age,occupation,zip_code',\n",
       " '1,F,1,10,48067',\n",
       " '2,M,56,16,70072',\n",
       " '3,M,25,15,55117',\n",
       " '4,M,45,7,02460']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile(os.path.join(data_folder, \"users.csv\")).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".filter(lambda x: \"zombie\" in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_fr = sc.textFile(os.path.join(data_folder, \"ratings.csv\")).map(lambda x: (x.split(\",\")[0], x.split(\",\")[1],1))\n",
    "f_users = sc.textFile(os.path.join(data_folder, \"users.csv\")).map(lambda x: (x.split(\",\")[0],x.split(\",\")[1])).filter(lambda x: x[1] == \"F\")\n",
    "ratings_fr_res = ratings_fr.join(f_users).map(lambda x: (x[1][0], 1)).reduceByKey(lambda x,y: x + y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_rf = sc.textFile(os.path.join(data_folder, \"ratings.csv\")).map(lambda x: (x.split(\",\")[0], x.split(\",\")[1],1))\n",
    "users = sc.textFile(os.path.join(data_folder, \"users.csv\")).map(lambda x: (x.split(\",\")[0],x.split(\",\")[1]))\n",
    "ratings_rf_res = ratings_rf.join(users).filter(lambda x: x[1][1] == \"F\").map(lambda x: (x[1][0], 1)).reduceByKey(lambda x,y: x + y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happened? Let's find out in Spark UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Working with RDD allows developers to have more freedom. \n",
    "- However, this is not recommended. There are new high-lever structured API that optimize many steps of the data transformations. \n",
    "- In general, it is pointless trying to beat a query optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_sc = sql.SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_file = os.path.join(data_folder, \"ratings.csv\")\n",
    "ratings = sql_sc.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(ratings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.createOrReplaceTempView(\"ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_file = os.path.join(data_folder, \"users.csv\")\n",
    "users = sql_sc.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(users_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.createOrReplaceTempView(\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlWay = sql_sc.sql(\"\"\"\n",
    "SELECT r.movie_id, count(r.rating)\n",
    "FROM ratings r\n",
    "INNER JOIN users u on r.user_id = u.user_id\n",
    "WHERE u.gender = 'F'\n",
    "GROUP BY r.movie_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrameWay = ratings.join(users, ratings.user_id == users.user_id).filter(users.gender == 'F') \\\n",
    "  .groupBy(ratings.movie_id).agg({\"rating\": \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394 ms ± 47.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sqlWay.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355 ms ± 38.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dataFrameWay.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*HashAggregate(keys=[movie_id#403], functions=[count(rating#404)])\n",
      "+- Exchange hashpartitioning(movie_id#403, 200)\n",
      "   +- *HashAggregate(keys=[movie_id#403], functions=[partial_count(rating#404)])\n",
      "      +- *Project [movie_id#403, rating#404]\n",
      "         +- *BroadcastHashJoin [user_id#402], [user_id#450], Inner, BuildRight\n",
      "            :- *Project [user_id#402, movie_id#403, rating#404]\n",
      "            :  +- *Filter isnotnull(user_id#402)\n",
      "            :     +- *FileScan csv [user_id#402,movie_id#403,rating#404] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/ubuntu/movielens_v2/movielens/ratings.csv], PartitionFilters: [], PushedFilters: [IsNotNull(user_id)], ReadSchema: struct<user_id:int,movie_id:int,rating:int>\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))\n",
      "               +- *Project [user_id#450]\n",
      "                  +- *Filter ((isnotnull(gender#451) && (gender#451 = F)) && isnotnull(user_id#450))\n",
      "                     +- *FileScan csv [user_id#450,gender#451] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/ubuntu/movielens_v2/movielens/users.csv], PartitionFilters: [], PushedFilters: [IsNotNull(gender), EqualTo(gender,F), IsNotNull(user_id)], ReadSchema: struct<user_id:int,gender:string>\n"
     ]
    }
   ],
   "source": [
    "sqlWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*HashAggregate(keys=[movie_id#403], functions=[count(rating#404)])\n",
      "+- Exchange hashpartitioning(movie_id#403, 200)\n",
      "   +- *HashAggregate(keys=[movie_id#403], functions=[partial_count(rating#404)])\n",
      "      +- *Project [movie_id#403, rating#404]\n",
      "         +- *BroadcastHashJoin [user_id#402], [user_id#450], Inner, BuildRight\n",
      "            :- *Project [user_id#402, movie_id#403, rating#404]\n",
      "            :  +- *Filter isnotnull(user_id#402)\n",
      "            :     +- *FileScan csv [user_id#402,movie_id#403,rating#404] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/ubuntu/movielens_v2/movielens/ratings.csv], PartitionFilters: [], PushedFilters: [IsNotNull(user_id)], ReadSchema: struct<user_id:int,movie_id:int,rating:int>\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))\n",
      "               +- *Project [user_id#450]\n",
      "                  +- *Filter ((isnotnull(gender#451) && (gender#451 = F)) && isnotnull(user_id#450))\n",
      "                     +- *FileScan csv [user_id#450,gender#451] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/ubuntu/movielens_v2/movielens/users.csv], PartitionFilters: [], PushedFilters: [IsNotNull(gender), EqualTo(gender,F), IsNotNull(user_id)], ReadSchema: struct<user_id:int,gender:string>\n"
     ]
    }
   ],
   "source": [
    "dataFrameWay.explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
